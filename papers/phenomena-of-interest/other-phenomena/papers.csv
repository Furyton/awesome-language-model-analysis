Title,Date,Url,Author
Algorithmic progress in language models,2024-03-09,http://arxiv.org/abs/2403.05812,Anson Ho; Tamay Besiroglu; Ege Erdil; David Owen; Robi Rahman; Zifan Carl Guo; David Atkinson; Neil Thompson; Jaime Sevilla
Massive Activations in Large Language Models,2024-02-27,http://arxiv.org/abs/2402.17762,Mingjie Sun; Xinlei Chen; J. Zico Kolter; Zhuang Liu
The Lazy Neuron Phenomenon: On Emergence of Activation Sparsity in Transformers,2023-02-01,https://openreview.net/forum?id=TJ2nxciYCk-,Zonglin Li; Chong You; Srinadh Bhojanapalli; Daliang Li; Ankit Singh Rawat; Sashank J. Reddi; Ke Ye; Felix Chern; Felix Yu; Ruiqi Guo; Sanjiv Kumar
The Platonic Representation Hypothesis,2024-05-13,https://arxiv.org/abs/2405.07987v1,Minyoung Huh; Brian Cheung; Tongzhou Wang; Phillip Isola
Your Transformer is Secretly Linear,2024-05-19,https://arxiv.org/abs/2405.12250,Anton Razzhigaev; Matvey Mikhalchuk; Elizaveta Goncharova; Nikolai Gerasimenko; Ivan Oseledets; Denis Dimitrov; Andrey Kuznetsov
Implicit Multimodal Alignment: On the Generalization of Frozen LLMs to Multimodal Inputs,2024-05-26,https://arxiv.org/abs/2405.16700,Mustafa Shukor; Matthieu Cord
Linguistic Collapse: Neural Collapse in (Large) Language Models,2024-05-28,https://arxiv.org/abs/2405.17767,Robert Wu; Vardan Papyan
Exploring Activation Patterns of Parameters in Language Models,2024-05-28,https://arxiv.org/abs/2405.17799,Yudong Wang; Damai Dai; Zhifang Sui