Title,Date,Url,Author
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,2024-04-25,http://arxiv.org/abs/2404.17120,Valeriia Cherepanova; James Zou
Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions,2024-02-22,http://arxiv.org/abs/2402.15055,Clement Neo; Shay B. Cohen; Fazl Barez
Universal Neurons in GPT2 Language Models,2024-01-22,http://arxiv.org/abs/2401.12181,Wes Gurnee; Theo Horsley; Zifan Carl Guo; Tara Rezaei Kheirkhah; Qinyi Sun; Will Hathaway; Neel Nanda; Dimitris Bertsimas
Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks,2023-11-21,http://arxiv.org/abs/2311.12786,Samyak Jain; Robert Kirk; Ekdeep Singh Lubana; Robert P. Dick; Hidenori Tanaka; Edward Grefenstette; Tim Rocktäschel; David Scott Krueger
Understanding the Mechanics and Dynamics of Memorisation in Large Language Models: A Case Study with Random Strings,2023-10-13,https://openreview.net/forum?id=ILStlRb1Sp,Till Speicher; Aflah Mohammad Khan; Qinyuan Wu; Vedant Nanda; Soumi Das; Bishwamittra Ghosh; Krishna P. Gummadi; Evimaria Terzi
Interpretability Illusions in the Generalization of Simplified Models,2023-12-06,http://arxiv.org/abs/2312.03656,Dan Friedman; Andrew Lampinen; Lucas Dixon; Danqi Chen; Asma Ghandeharioun
Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars,2023-12-03,http://arxiv.org/abs/2312.01429,Kaiyue Wen; Yuchen Li; Bingbin Liu; Andrej Risteski
White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?,2023-11-22,https://arxiv.org/abs/2311.13110v2,Yaodong Yu; Sam Buchanan; Druv Pai; Tianzhe Chu; Ziyang Wu; Shengbang Tong; Hao Bai; Yuexiang Zhai; Benjamin D. Haeffele; Yi Ma
A Primer on the Inner Workings of Transformer-based Language Models,2024-05-02,https://arxiv.org/abs/2405.00208,Javier Ferrando; Gabriele Sarti; Arianna Bisazza; Marta R. Costa-jussà
Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions,2024-05-06,https://arxiv.org/abs/2405.03205,Ruizhe Li; Yanjun Gao
Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers,2024-05-22,http://arxiv.org/abs/2405.13536,Tobias Leemann; Alina Fastowski; Felix Pfeiffer; Gjergji Kasneci
Not All Language Model Features Are Linear,2024-05-23,http://arxiv.org/abs/2405.14860,Joshua Engels; Isaac Liao; Eric J. Michaud; Wes Gurnee; Max Tegmark
Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models,2024-05-21,http://arxiv.org/abs/2405.12522,Charles O'Neill; Thang Bui
From Neurons to Neutrons: A Case Study in Interpretability,2024-05-27,http://arxiv.org/abs/2405.17425,Ouail Kitouni; Niklas Nolte; Víctor Samuel Pérez-Díaz; Sokratis Trifinopoulos; Mike Williams
Mechanistic Interpretability of Binary and Ternary Transformers,2024-05-27,http://arxiv.org/abs/2405.17703,Jason Li
InversionView: A General-Purpose Method for Reading Information from Neural Activations,2024-05-27,http://arxiv.org/abs/2405.17653,Xinting Huang; Madhur Panwar; Navin Goyal; Michael Hahn
Scaling and evaluating sparse autoencoders,2024-06-06,http://arxiv.org/abs/2406.04093,Leo Gao; Tom Dupré la Tour; Henk Tillman; Gabriel Goh; Rajan Troll; Alec Radford; Ilya Sutskever; Jan Leike; Jeffrey Wu
Interpreting Attention Layer Outputs with Sparse Autoencoders,2024-06-25,http://arxiv.org/abs/2406.17759,Connor Kissane; Robert Krzyzanowski; Joseph Isaac Bloom; Arthur Conmy; Neel Nanda
Talking Heads: Understanding Inter-layer Communication in Transformer Language Models,2024-06-13,http://arxiv.org/abs/2406.09519,Jack Merullo; Carsten Eickhoff; Ellie Pavlick
From RAGs to rich parameters: Probing how language models utilize external knowledge over parametric information for factual queries,2024-06-18,http://arxiv.org/abs/2406.12824,Hitesh Wadhwa; Rahul Seetharaman; Somyaa Aggarwal; Reshmi Ghosh; Samyadeep Basu; Soundararajan Srinivasan; Wenlong Zhao; Shreyas Chaudhari; Ehsan Aghazadeh
Insights into LLM Long-Context Failures: When Transformers Know but Don't Tell,2024-06-20,http://arxiv.org/abs/2406.14673,Taiming Lu; Muhan Gao; Kuai Yu; Adam Byerly; Daniel Khashabi
Confidence Regulation Neurons in Language Models,2024-06-24,http://arxiv.org/abs/2406.16254,Alessandro Stolfo; Ben Wu; Wes Gurnee; Yonatan Belinkov; Xingyi Song; Mrinmaya Sachan; Neel Nanda
Finding Transformer Circuits with Edge Pruning,2024-06-24,http://arxiv.org/abs/2406.16778,Adithya Bhaskar; Alexander Wettig; Dan Friedman; Danqi Chen
Unlocking the Future: Exploring Look-Ahead Planning Mechanistic Interpretability in Large Language Models,2024-06-23,http://arxiv.org/abs/2406.16033,Tianyi Men; Pengfei Cao; Zhuoran Jin; Yubo Chen; Kang Liu; Jun Zhao
Large Language Models are Interpretable Learners,2024-06-25,http://arxiv.org/abs/2406.17224,Ruochen Wang; Si Si; Felix Yu; Dorothea Wiesmann; Cho-Jui Hsieh; Inderjit Dhillon
Transformer Normalisation Layers and the Independence of Semantic Subspaces,2024-06-25,http://arxiv.org/abs/2406.17837,Stephen Menary; Samuel Kaski; Andre Freitas
Refusal in Language Models Is Mediated by a Single Direction,2024-06-17,http://arxiv.org/abs/2406.11717,Andy Arditi; Oscar Obeso; Aaquib Syed; Daniel Paleka; Nina Panickssery; Wes Gurnee; Neel Nanda
Clustering in pure-attention hardmax transformers and its role in sentiment analysis,2024-06-26,http://arxiv.org/abs/2407.01602,Albert Alcalde; Giovanni Fantuzzi; Enrique Zuazua
Observable Propagation: Uncovering Feature Vectors in Transformers,2024-06-04,http://arxiv.org/abs/2406.16291,Jacob Dunefsky; Arman Cohan
"Answer, Assemble, Ace: Understanding How Transformers Answer Multiple Choice Questions",2024-07-21,http://arxiv.org/abs/2407.15018,Sarah Wiegreffe; Oyvind Tafjord; Yonatan Belinkov; Hannaneh Hajishirzi; Ashish Sabharwal
Transformer Layers as Painters,2024-07-12,http://arxiv.org/abs/2407.09298,Qi Sun; Marc Pickett; Aakash Kumar Nain; Llion Jones
Monitoring Latent World States in Language Models with Propositional Probes,2024-06-27,http://arxiv.org/abs/2406.19501,Jiahai Feng; Stuart Russell; Jacob Steinhardt
GiLOT: Interpreting Generative Language Models via Optimal Transport,2024-05-02,https://openreview.net/pdf?id=qKL25sGjxL,Xuhong Li; Jiamin Chen; Yekun Chai; Haoyi Xiong
A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models,2024-08-16,http://arxiv.org/abs/2408.08590,Geonhee Kim; Marco Valentino; André Freitas
Monotonic Representation of Numeric Properties in Language Models,2024-08-15,http://arxiv.org/abs/2408.10381,Benjamin Heinzerling; Kentaro Inui
The Mechanics of Conceptual Interpretation in GPT Models: Interpretative Insights,2024-08-05,http://arxiv.org/abs/2408.11827,Nura Aljaafari; Danilo S. Carvalho; André Freitas
A Mechanistic Interpretation of Syllogistic Reasoning in Auto-Regressive Language Models,2024-08-16,http://arxiv.org/abs/2408.08590,Geonhee Kim; Marco Valentino; André Freitas
Transformer Circuit Faithfulness Metrics are not Robust,2024-07-11,http://arxiv.org/abs/2407.08734,Joseph Miller; Bilal Chughtai; William Saunders
LLM Circuit Analyses Are Consistent Across Training and Scale,2024-07-15,http://arxiv.org/abs/2407.10827,Curt Tigges; Michael Hanna; Qinan Yu; Stella Biderman
Modularity in Transformers: Investigating Neuron Separability & Specialization,2024-08-30,http://arxiv.org/abs/2408.17324,Nicholas Pochinkov; Thomas Jones; Mohammed Rashidur Rahman
Extracting Paragraphs from LLM Token Activations,2024-09-10,http://arxiv.org/abs/2409.06328,Nicholas Pochinkov; Angelo Benoit; Lovkush Agarwal; Zainab Ali Majid; Lucile Ter-Minassian
Explaining Datasets in Words: Statistical Models with Natural Language Parameters,2024-09-13,http://arxiv.org/abs/2409.08466,Ruiqi Zhong; Heng Wang; Dan Klein; Jacob Steinhardt
Optimal ablation for interpretability,2024-09-16,http://arxiv.org/abs/2409.09951,Maximilian Li; Lucas Janson