Title,Date,Url,Author
Talking Nonsense: Probing Large Language Models' Understanding of Adversarial Gibberish Inputs,2024-04-25,http://arxiv.org/abs/2404.17120,Valeriia Cherepanova; James Zou
Interpreting Context Look-ups in Transformers: Investigating Attention-MLP Interactions,2024-02-22,http://arxiv.org/abs/2402.15055,Clement Neo; Shay B. Cohen; Fazl Barez
Universal Neurons in GPT2 Language Models,2024-01-22,http://arxiv.org/abs/2401.12181,Wes Gurnee; Theo Horsley; Zifan Carl Guo; Tara Rezaei Kheirkhah; Qinyi Sun; Will Hathaway; Neel Nanda; Dimitris Bertsimas
Mechanistically analyzing the effects of fine-tuning on procedurally defined tasks,2023-11-21,http://arxiv.org/abs/2311.12786,Samyak Jain; Robert Kirk; Ekdeep Singh Lubana; Robert P. Dick; Hidenori Tanaka; Edward Grefenstette; Tim Rocktäschel; David Scott Krueger
Understanding the Mechanics and Dynamics of Memorisation in Large Language Models: A Case Study with Random Strings,2023-10-13,https://openreview.net/forum?id=ILStlRb1Sp,Till Speicher; Aflah Mohammad Khan; Qinyuan Wu; Vedant Nanda; Soumi Das; Bishwamittra Ghosh; Krishna P. Gummadi; Evimaria Terzi
Interpretability Illusions in the Generalization of Simplified Models,2023-12-06,http://arxiv.org/abs/2312.03656,Dan Friedman; Andrew Lampinen; Lucas Dixon; Danqi Chen; Asma Ghandeharioun
Transformers are uninterpretable with myopic methods: a case study with bounded Dyck grammars,2023-12-03,http://arxiv.org/abs/2312.01429,Kaiyue Wen; Yuchen Li; Bingbin Liu; Andrej Risteski
White-Box Transformers via Sparse Rate Reduction: Compression Is All There Is?,2023-11-22,https://arxiv.org/abs/2311.13110v2,Yaodong Yu; Sam Buchanan; Druv Pai; Tianzhe Chu; Ziyang Wu; Shengbang Tong; Hao Bai; Yuexiang Zhai; Benjamin D. Haeffele; Yi Ma
A Primer on the Inner Workings of Transformer-based Language Models,2024-05-02,https://arxiv.org/abs/2405.00208,Javier Ferrando; Gabriele Sarti; Arianna Bisazza; Marta R. Costa-jussà
Anchored Answers: Unravelling Positional Bias in GPT-2's Multiple-Choice Questions,2024-05-06,https://arxiv.org/abs/2405.03205,Ruizhe Li; Yanjun Gao
Attention Mechanisms Don't Learn Additive Models: Rethinking Feature Importance for Transformers,2024-05-22,http://arxiv.org/abs/2405.13536,Tobias Leemann; Alina Fastowski; Felix Pfeiffer; Gjergji Kasneci
Not All Language Model Features Are Linear,2024-05-23,http://arxiv.org/abs/2405.14860,Joshua Engels; Isaac Liao; Eric J. Michaud; Wes Gurnee; Max Tegmark
Sparse Autoencoders Enable Scalable and Reliable Circuit Identification in Language Models,2024-05-21,http://arxiv.org/abs/2405.12522,Charles O'Neill; Thang Bui
From Neurons to Neutrons: A Case Study in Interpretability,2024-05-27,http://arxiv.org/abs/2405.17425,Ouail Kitouni; Niklas Nolte; Víctor Samuel Pérez-Díaz; Sokratis Trifinopoulos; Mike Williams
Mechanistic Interpretability of Binary and Ternary Transformers,2024-05-27,http://arxiv.org/abs/2405.17703,Jason Li
InversionView: A General-Purpose Method for Reading Information from Neural Activations,2024-05-27,http://arxiv.org/abs/2405.17653,Xinting Huang; Madhur Panwar; Navin Goyal; Michael Hahn
Scaling and evaluating sparse autoencoders,2024-06-06,http://arxiv.org/abs/2406.04093,Leo Gao; Tom Dupré la Tour; Henk Tillman; Gabriel Goh; Rajan Troll; Alec Radford; Ilya Sutskever; Jan Leike; Jeffrey Wu